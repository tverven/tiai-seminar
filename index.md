---
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults

# title: Theory of Interpretable AI Seminar
layout: home
---

The seminar is an international online event focused on exploring the theoretical foundations of interpretable and explainable AI. Its goal is to exchange ideas and form a supportive community for those interested in the topic. 

## Practicalities

* Monthly seminar, 15.00 Central European Time (CET) /
  9.00 am Eastern Standard Time (EST)
* Zoom link: [https://uva-live.zoom.us/j/87120549999](https://uva-live.zoom.us/j/87120549999)
* Sign up:
    * [E-mail announcements](https://list.uva.nl/mailman/listinfo/tiai-seminar)
    * [Google calendar](https://calendar.google.com/calendar/u/1?cid=NTlhNjNhZDQ5ZmUxYmM5MmRmZTMwNzkwOWZhYjMyNTRhMzA4OGYwZTAxY2Q5MGU3NzQ2YjRlNWE0NzhmMzFkMUBncm91cC5jYWxlbmRhci5nb29nbGUuY29t)

### Organizers:
* [Michal Moshkovitz](https://sites.google.com/view/michal-moshkovitz/home)
* [Suraj Srinivas](https://suraj-srinivas.github.io/)
* [Tim van Erven](https://www.timvanerven.nl/)

## Schedule

### 2024/2025

<table>
<tr>
<td>October&nbsp;10</td>
<td><a href="http://tml.cs.uni-tuebingen.de/team/luxburg/">Ulrike von Luxburg</a></td>
<td>...</td>
<td>
    <details>
        <summary>Abstract</summary>
        <p>...</p>
    </details>
</td>
</tr>

<tr>
<td>September&nbsp;5</td>
<td>TBA</td>
<td>...</td>
<td>
    <details>
        <summary>Abstract</summary>
        <p>...</p>
    </details>
</td>
</tr>
</table>

### 2023/2024

<table>
<tr>
<td>July&nbsp;11</td>
<td><a href="https://cseweb.ucsd.edu/~dasgupta/">Sanjoy Dasgupta</a></td>
<td>...</td>
<td>
    <details>
        <summary>Abstract</summary>
        <p>...</p>
    </details>
</td>
</tr>

<tr>
<td>June&nbsp;20</td>
<td>TBA</td>
<td>...</td>
<td>
    <details>
        <summary>Abstract</summary>
        <p>...</p>
    </details>
</td>
</tr>

<tr>
<td>May&nbsp;23</td>
<td>TBA</td>
<td>...</td>
<td>
    <details>
        <summary>Abstract</summary>
        <p>...</p>
    </details>
</td>
</tr>


<tr>
<td>April&nbsp;4</td>
<td><a href="https://sites.google.com/view/damien-garreau/home">Damien Garreau</a></td>
<td>
A Sea of Words: An In-Depth Analysis of Anchors for Text Data
</td>
<td>
    <details>
        <summary>Abstract</summary>
        <p>
        Anchors (Ribeiro et al., 2018) is a post-hoc, rule-based
        interpretability method. For text data, it proposes to explain a
        decision by highlighting a small set of words (an anchor) such
        that the model to explain has similar outputs when they are
        present in a document. In this talk, I will present a first
        attempt to theoretically understand Anchors, considering that
        the search for the best anchor is exhaustive. I will give
        explicit results on shortcut models and linear models when the
        vectorization step is TF-IDF, and word replacement is a fixed
        out-of-dictionary token. 
        <br>
        Paper: <a href="https://proceedings.mlr.press/v206/lopardo23a.html">https://proceedings.mlr.press/v206/lopardo23a.html</a>
        </p>
    </details>
</td>
</tr>

</table>
